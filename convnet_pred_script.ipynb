{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspired by this:\n",
    "# https://www.kaggle.com/bguberfain/naive-keras-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import collections\n",
    "import copy\n",
    "import cProfile\n",
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import operator\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import Image\n",
    "import keras\n",
    "from keras import *\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL as pil\n",
    "import pylab\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "import statsmodels as sm\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/media/ntfs/data/carvana_masking'\n",
    "\n",
    "input_dir = data_dir + '/input'\n",
    "tmp_dir = data_dir + '/tmp'\n",
    "output_dir = data_dir + '/output'\n",
    "\n",
    "train_dir = input_dir + '/train'\n",
    "train_mask_dir = input_dir + '/train_masks'\n",
    "\n",
    "val_dir = input_dir + '/validation'\n",
    "val_mask_dir = input_dir + '/validation_masks'\n",
    "\n",
    "test_dir = input_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angle = int(sys.argv[1])\n",
    "\n",
    "resize_h = 160\n",
    "resize_w = 240\n",
    "\n",
    "n_train = 256  # max: 257\n",
    "n_val = 16     # max: 61\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "smooth = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = list(set([name[:12] for name in os.listdir(train_dir)]))\n",
    "random.shuffle(train_ids)\n",
    "train_ids = train_ids[:n_train]\n",
    "\n",
    "val_ids = list(set([name[:12] for name in os.listdir(val_dir)]))\n",
    "random.shuffle(val_ids)\n",
    "val_ids = val_ids[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(id, angle, val=False):\n",
    "    \n",
    "    dir = train_dir\n",
    "    if val:\n",
    "        dir = val_dir\n",
    "        \n",
    "    img = image.load_img(\n",
    "            dir + '/{0}_{1:02d}.jpg'.format(id, angle),\n",
    "            target_size=(resize_h, resize_w))\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "def load_mask(id, angle, val=False):\n",
    "    dir = train_mask_dir\n",
    "    if val:\n",
    "        dir = val_mask_dir\n",
    "        \n",
    "    img = image.load_img(\n",
    "            dir + '/{0}_{1:02d}_mask.gif'.format(id, angle),\n",
    "            target_size=(resize_h, resize_w))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img[:,:,0]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(n, angle=angle, val=False):\n",
    "    \n",
    "    dir = train_dir\n",
    "    mask_dir = train_mask_dir\n",
    "    ids = train_ids\n",
    "    if val:\n",
    "        dir = val_dir\n",
    "        mask_dir = val_mask_dir\n",
    "        ids = val_ids\n",
    "    \n",
    "    X = np.empty((n, resize_h, resize_w, 12), dtype=np.float32)\n",
    "    y = np.empty((n, resize_h, resize_w, 1), dtype=np.float32)\n",
    "    \n",
    "    with tqdm.tqdm_notebook(total=n) as bar:\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            imgs = [load_image(ids[i], a, val) for a in range(1, 17)]\n",
    "            X[i, ..., :9] = np.concatenate([imgs[angle-1], np.mean(imgs, axis=0), np.std(imgs, axis=0)], axis=2)\n",
    "            y[i] = np.expand_dims(load_mask(ids[i], angle, val), 2) / 255.\n",
    "            \n",
    "            del imgs\n",
    "            \n",
    "            bar.update()\n",
    "            \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec26c35392544f89d64e32bdb1da3f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1c8bc194504cd28fa9df69a66d724f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data(n_train)\n",
    "X_val, y_val = load_data(n_val, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_mean = y_train.mean(axis=0)\n",
    "y_train_std = y_train.std(axis=0)\n",
    "y_train_min = y_train.min(axis=0)\n",
    "\n",
    "y_features = np.concatenate([y_train_mean, y_train_std, y_train_min], axis=2)\n",
    "\n",
    "X_train[:, ..., -3:] = y_features\n",
    "X_val[:, ..., -3:] = y_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mean = X_train.mean(axis=(0,1,2), keepdims=True)\n",
    "X_std = X_train.std(axis=(0,1,2), keepdims=True)\n",
    "\n",
    "X_train -= X_mean\n",
    "X_train /= X_std\n",
    "\n",
    "X_val -= X_mean\n",
    "X_val /= X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding More Layers to Bruno's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 160, 240, 12)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 160, 240, 12)  1308        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 80, 120, 12)   0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 80, 120, 12)   1308        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 80, 120, 12)   1308        conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 40, 60, 12)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 40, 60, 12)    1308        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, 160, 240, 12)  1308        conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, 160, 240, 12)  1308        conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 160, 240, 36)  0           conv2d_2[0][0]                   \n",
      "                                                                   conv2d_transpose_1[0][0]         \n",
      "                                                                   conv2d_transpose_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 160, 240, 1)   1765        concatenate_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 9,613\n",
      "Trainable params: 9,613\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = keras.layers.Input((resize_h, resize_w, 12))\n",
    "\n",
    "conv1 = keras.layers.Conv2D(12, 3, activation='relu', padding='same')(inp)\n",
    "conv2 = keras.layers.Conv2D(12, 3, activation='relu', padding='same')(inp)\n",
    "max1 = keras.layers.MaxPooling2D(2)(conv2)\n",
    "\n",
    "conv3 = keras.layers.Conv2D(12, 3, activation='relu', padding='same')(max1)\n",
    "conv4 = keras.layers.Conv2D(12, 3, activation='relu', padding='same')(conv3)\n",
    "max2 = keras.layers.MaxPooling2D(2)(conv4)\n",
    "\n",
    "conv5 = keras.layers.Conv2D(12, 3, activation='relu', padding='same')(max2)\n",
    "\n",
    "deconv4 = keras.layers.Conv2DTranspose(12, 3, strides=2, activation='relu', padding='same')(conv4)\n",
    "deconv5 = keras.layers.Conv2DTranspose(12, 3, strides=4, activation='relu', padding='same')(conv5)\n",
    "\n",
    "deconvs = keras.layers.concatenate([conv2, deconv4, deconv5])\n",
    "\n",
    "out = keras.layers.Conv2D(1, 7, activation='sigmoid', padding='same')(deconvs)\n",
    "\n",
    "model = keras.models.Model(inp, out)\n",
    "\n",
    "model.compile(keras.optimizers.Adam(lr=1e-3), dice_loss, metrics=['accuracy', dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train,\n",
    "            epochs=epochs,\n",
    "            validation_data=(X_val, y_val),\n",
    "            batch_size=batch_size,\n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_image(id, angle):\n",
    "    \n",
    "    dir = test_dir\n",
    "        \n",
    "    img = image.load_img(\n",
    "            dir + '/{0}_{1:02d}.jpg'.format(id, angle),\n",
    "            target_size=(resize_h, resize_w))\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from here:\n",
    "# https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "\n",
    "def rle_encode(mask_image):\n",
    "    pixels = mask_image.flatten()\n",
    "    # We avoid issues with '1' at the start or end (at the corners of \n",
    "    # the original image) by setting those pixels to '0' explicitly.\n",
    "    # We do not expect these to be non-zero for an accurate mask, \n",
    "    # so this should not harm the score.\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    return runs\n",
    "\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af07a9115864a64a9c223b33fffb7fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_ids = list(set([name[:12] for name in os.listdir(test_dir)]))#[:10]\n",
    "n_test = len(test_ids)\n",
    "\n",
    "with tqdm.tqdm_notebook(total=n_test) as bar:\n",
    "\n",
    "    with open('pred_rle_{0:02d}.csv'.format(angle), 'w') as f:\n",
    "        for id in test_ids:\n",
    "\n",
    "            x = np.empty((resize_h, resize_w, 12), dtype=np.float32)\n",
    "\n",
    "            imgs = [load_test_image(id, a) for a in range(1, 17)]\n",
    "\n",
    "            x[..., :9] = np.concatenate([imgs[angle-1], np.mean(imgs, axis=0), np.std(imgs, axis=0)], axis=2)\n",
    "            del imgs\n",
    "\n",
    "            x[..., -3:] = y_features\n",
    "\n",
    "            x -= X_mean[0]\n",
    "            x /= X_std[0]\n",
    "\n",
    "            y_pred = model.predict(x[None]).squeeze()\n",
    "            del x\n",
    "\n",
    "            y_pred_rgb = np.zeros((resize_h, resize_w, 3))\n",
    "            y_pred_rgb[..., 0] = y_pred\n",
    "            y_pred_rgb[..., 1] = y_pred\n",
    "            y_pred_rgb[..., 2] = y_pred\n",
    "\n",
    "            y_pred_resized = (image.img_to_array(\n",
    "                image.array_to_img(y_pred_rgb).resize((1918, 1280), Image.BILINEAR))[..., 0] > 0.5)\n",
    "            del y_pred\n",
    "            del y_pred_rgb\n",
    "\n",
    "            f.write('{0}_{1:02d}.jpg,{2}\\n'.format(id, angle, rle_to_string(rle_encode(y_pred_resized))))\n",
    "\n",
    "            del y_pred_resized\n",
    "\n",
    "            bar.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
